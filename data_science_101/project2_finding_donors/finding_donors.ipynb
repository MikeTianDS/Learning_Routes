{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 监督学习\n",
    "## 项目2: 为*CharityML*寻找捐献者"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始\n",
    "\n",
    "在这个项目中，你将使用1994年美国人口普查收集的数据，选用几个监督学习算法以准确地建模被调查者的收入。然后，你将根据初步结果从中选择出最佳的候选算法，并进一步优化该算法以最好地建模这些数据。你的目标是建立一个能够准确地预测被调查者年收入是否超过50000美元的模型。这种类型的任务会出现在那些依赖于捐款而存在的非营利性组织。了解人群的收入情况可以帮助一个非营利性的机构更好地了解他们要多大的捐赠，或是否他们应该接触这些人。虽然我们很难直接从公开的资源中推断出一个人的一般收入阶层，但是我们可以（也正是我们将要做的）从其他的一些公开的可获得的资源中获得一些特征从而推断出该值。\n",
    "\n",
    "这个项目的数据集来自[UCI机器学习知识库](https://archive.ics.uci.edu/ml/datasets/Census+Income)。这个数据集是由Ron Kohavi和Barry Becker在发表文章_\"Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid\"_之后捐赠的，你可以在Ron Kohavi提供的[在线版本](https://www.aaai.org/Papers/KDD/1996/KDD96-033.pdf)中找到这个文章。我们在这里探索的数据集相比于原有的数据集有一些小小的改变，比如说移除了特征`'fnlwgt'` 以及一些遗失的或者是格式不正确的记录。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 探索数据\n",
    "运行下面的代码单元以载入需要的Python库并导入人口普查数据。注意数据集的最后一列`'income'`将是我们需要预测的列（表示被调查者的年收入会大于或者是最多50,000美元），人口普查数据中的每一列都将是关于被调查者的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass education_level  education-num  marital-status  \\\n",
       "0   39   State-gov       Bachelors           13.0   Never-married   \n",
       "\n",
       "      occupation    relationship    race    sex  capital-gain  capital-loss  \\\n",
       "0   Adm-clerical   Not-in-family   White   Male        2174.0           0.0   \n",
       "\n",
       "   hours-per-week  native-country income  \n",
       "0            40.0   United-States  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 为这个项目导入需要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display # 允许为DataFrame使用display()\n",
    "\n",
    "# 导入附加的可视化代码visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "# 为notebook提供更加漂亮的可视化\n",
    "%matplotlib inline\n",
    "\n",
    "# 导入人口普查数据\n",
    "data = pd.read_csv(\"census.csv\")\n",
    "\n",
    "# 成功 - 显示第一条记录\n",
    "display(data.head(n=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习：数据探索\n",
    "首先我们对数据集进行一个粗略的探索，我们将看看每一个类别里会有多少被调查者？并且告诉我们这些里面多大比例是年收入大于50,000美元的。在下面的代码单元中，你将需要计算以下量：\n",
    "\n",
    "- 总的记录数量，`'n_records'`\n",
    "- 年收入大于50,000美元的人数，`'n_greater_50k'`.\n",
    "- 年收入最多为50,000美元的人数 `'n_at_most_50k'`.\n",
    "- 年收入大于50,000美元的人所占的比例， `'greater_percent'`.\n",
    "\n",
    "**提示：** 您可能需要查看上面的生成的表，以了解`'income'`条目的格式是什么样的。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>9th</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass education_level  education-num  \\\n",
       "0   39          State-gov       Bachelors           13.0   \n",
       "1   50   Self-emp-not-inc       Bachelors           13.0   \n",
       "2   38            Private         HS-grad            9.0   \n",
       "3   53            Private            11th            7.0   \n",
       "4   28            Private       Bachelors           13.0   \n",
       "5   37            Private         Masters           14.0   \n",
       "6   49            Private             9th            5.0   \n",
       "7   52   Self-emp-not-inc         HS-grad            9.0   \n",
       "\n",
       "           marital-status          occupation    relationship    race  \\\n",
       "0           Never-married        Adm-clerical   Not-in-family   White   \n",
       "1      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3      Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4      Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "5      Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "6   Married-spouse-absent       Other-service   Not-in-family   Black   \n",
       "7      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country income  \n",
       "0     Male        2174.0           0.0            40.0   United-States  <=50K  \n",
       "1     Male           0.0           0.0            13.0   United-States  <=50K  \n",
       "2     Male           0.0           0.0            40.0   United-States  <=50K  \n",
       "3     Male           0.0           0.0            40.0   United-States  <=50K  \n",
       "4   Female           0.0           0.0            40.0            Cuba  <=50K  \n",
       "5   Female           0.0           0.0            40.0   United-States  <=50K  \n",
       "6   Female           0.0           0.0            16.0         Jamaica  <=50K  \n",
       "7     Male           0.0           0.0            45.0   United-States   >50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 45222\n",
      "Individuals making more than $50,000: 11208\n",
      "Individuals making at most $50,000: 34014\n",
      "Percentage of individuals making more than $50,000: 24.78%\n"
     ]
    }
   ],
   "source": [
    "# TODO：总的记录数\n",
    "n_records = data.shape[0]\n",
    "\n",
    "# TODO：被调查者的收入大于$50,000的人数\n",
    "df_50kup = data[data['income']=='>50K'].shape[0]\n",
    "n_greater_50k = df_50kup\n",
    "\n",
    "# TODO：被调查者的收入最多为$50,000的人数\n",
    "n_at_most_50k = data[data['income']=='<=50K'].shape[0]\n",
    "\n",
    "# TODO：被调查者收入大于$50,000所占的比例\n",
    "greater_percent = float(n_greater_50k)*100 / (n_greater_50k + n_at_most_50k)\n",
    "\n",
    "# 打印结果\n",
    "print (\"Total number of records: {}\".format(n_records))\n",
    "print (\"Individuals making more than $50,000: {}\".format(n_greater_50k))\n",
    "print (\"Individuals making at most $50,000: {}\".format(n_at_most_50k))\n",
    "print (\"Percentage of individuals making more than $50,000: {:.2f}%\".format(greater_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 准备数据\n",
    "在数据能够被作为输入提供给机器学习算法之前，它经常需要被清洗，格式化，和重新组织 - 这通常被叫做**预处理**。幸运的是，对于这个数据集，没有我们必须处理的无效或丢失的条目，然而，由于某一些特征存在的特性我们必须进行一定的调整。这个预处理都可以极大地帮助我们提升几乎所有的学习算法的结果和预测能力。\n",
    "\n",
    "### 获得特征和标签\n",
    "`income` 列是我们需要的标签，记录一个人的年收入是否高于50K。 因此我们应该把他从数据中剥离出来，单独存放。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据切分成特征和对应的标签\n",
    "income_raw = data['income']\n",
    "features_raw = data.drop('income', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转换倾斜的连续特征\n",
    "\n",
    "一个数据集有时可能包含至少一个靠近某个数字的特征，但有时也会有一些相对来说存在极大值或者极小值的不平凡分布的的特征。算法对这种分布的数据会十分敏感，并且如果这种数据没有能够很好地规一化处理会使得算法表现不佳。在人口普查数据集的两个特征符合这个描述：'`capital-gain'`和`'capital-loss'`。\n",
    "\n",
    "运行下面的代码单元以创建一个关于这两个特征的条形图。请注意当前的值的范围和它们是如何分布的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAF2CAYAAAD+y36TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xe8PUV9//HXmypFARWQAAoSIhpjRcVgFDtiIZYYjMgX7FETjfpTrCC2qFEDMbYoAZXYsCGiiAh2pUkTpSigIE1AadLn98fM4bvfwy17v997bjuv5+NxHvfs7Jzd2d1zd85nZ3Y2pRQkSZIkqY/V5rsAkiRJkhYPAwhJkiRJvRlASJIkSerNAEKSJElSbwYQkiRJknozgJAkSZLUmwGE5lWSv0/y/SSXJvlzkvOTfDXJzp08eyYpSf5yPsu6sjrl32qafAe1fCXJrUn+lOSMJJ9M8vCVXe4En3n+DMt/UJLzOtNbtfW+cCbLWZlyrcw2LiRJVkvyn0kuasf0q9PkXy/JG5KclOTqJNcnOTPJh0b5/U+yb5LHTJC+wrFf6pLcve3rs9u+vybJ8UnelGSD+S7fqHTOOyXJTUkuS/KDJG9JsskqLHfC79UqlnXfofJ2XyP5H1mZ86a01K0x3wXQ+Eryr8D+wIHA+4BrgW2AJwOPAb41f6WbN5cBT2vv1wPuBewO/DjJu0spb+zk/QbwcOCiGSx/T+r//YEz+MzbqcdplPZk4nKtzDYuJM8CXgm8BvgJcPlkGZNsBnwH+AvgQ8APgRuB+wDPB3YEHjiicu4DvBP47lD6XBz7BSHJI4HDgEuBA4DTgTWBHYCXA3cF/m3eCjh6BwEfo15YvAt1u/8F+Ncku5ZSfrwSy5zsezUbHgHcMpT2uxGsB1buvCktaQYQmk+vBb5aSnlBJ+27wP8kGdfWsRtLKT/tTB+d5CPAB4E3JDmxlPIlgFLKZdSAYySSrF1KuaGU8utRrWM6o97GOXDv9vc/Sym3TpP308BmwENLKWd30o9J8mFg11EUcCrzeeznUpKNgEOBXwKPK6Vc25n97STvB/52Xgo3dy4cOvd8PckBwA+ALye5Zynlunkq20R+Vkq5eb4LsbKSrAncXHyarxapcf2RpoXhzsDFE82Y7sdWku2TXJLky0nu0NLWaN0/fpXkhiS/T/L+wfyW57Qkn+hMb5Dk5iQXDC3/R0m+2Jmedtkt3z2TfCPJda0bwP7A2jPZKRPsiwK8DrgEeFVnXbfr3pPkn5L8vHW9uKpt70vavGOBRwE7dpr8jx1a1iOTfDHJH4GftXmTdWNZK8kHUrufXZfk8OGuRm2Z+w6lDbpA7TmDcnW3cc0k70hyXpIb2993tAp5eB0vSbJfaheiPyb5epIthsoz6T6bSpKdk/wktevdn1K73t2rM/88YLDtt3S3eYJlPQR4LPCuoeABqN+BUspXO/lnbR8kGfyAeVNn/+/b5k3Wfa3Pfp322HfSd09ySmq3oT8k+XRqi8yMl5fkIUmOSnJ5Oza/SQ3ApvJCYGPgX4aCBwBKKdeWUo7qrGPdJO9Jcm7b/+emdnNarZNnp1a2p6V2i/pDe30myYZD2/HKJL9s5b0yyQlJnt6Zf16Sg4bLNbxPkvxVkq+0/8nrk/w29f95pS4WllIuAf4fsCnwnM56npDkiHb8r0tyepLXJFm9W7b2dqLv1UOSHJrkgrbNZyZ5V5J1VqacE0mydZJDUs/DNyQ5ubtPW56/bN+1czvflY+kBpSDPMcy+flp3852dpc72f/Ny5K8N8nvgRuADWdQ1lk9ttKq8oun+XQcsCzJb4CvlVLO6vOhJE8AvgQcAry8lDJoxv4M8FTgPcCPqVd/3w5sBTyz5TkGeEpncTtRu4lsnuSvSilnJVkfeAi168nAtMtOshZwFLAOtcvDpcBLgGf02a6plFJuTHI08Kwka0x05S3JI1o5D6BW+qsB29EqKeBlbf7qrVwAVw0t5hDgs9SuN9OdH94AnAzsBWwCvIt6tfavSyk3zWDz+pSr62Dg2W19P6ReGX4TcE/gnyYo44+pXYA2Ad7f1rUT9NpnE0q9R+cb1BazfwTWB/YDfpjkAaWUC4GnA/9K7f4wuIdlsiv6j29/D5tqvR2ztg9a2X7C8i4sACsE1BOYbpm9JXlxW+/n23L/om3Xw5I8qJRyzQyWtT5wJPXcsidwNfV/dLrWg8cDF5VSTuixjjXaOu5DPQecRu3u8xbqRZHXDH1kf+Bw6nG5F/BeatebZW15z6Xuv/2oV/vXAe7XljVT3wCuBP4Z+AOwObALq3ax8NvAzdQudJ9safcEjgb+C7ge2J4aLG8M7N3yTPW9ujv13HEQ9Rj9NfDWttzdepZr9STd6VsHF56SbEm9AHIptdvZZdT/0y8l+ftSyuD/7C+o3Z5eRd1v9wTeCBzB8v/ZmZ6fpvIm4HjgxW1518+grKM4ttLKK6X48jUvL+CvgFOB0l5/oP54fcJQvj3b/L8Enkv9wf+2oTx/1/LsMZT+3Jb+gDb99DZ9jzb9n9QfbWcDL2lpO7c8281w2S9q0zt08qwG/KKlbzXN/jgIuGCK+e9uy9l0aL9s1aZfC1wxzTqOBX44QfpgWR+cpFzndaa3annPAFbrpO/Y0l/QSSvAvkPLG3x+zxmUa7CN951kmW9u6fcbWsexQ/le29L/ou8+m2Q/ntC+M2t00rYGbgI+0El7B60RaZrlfaSVa+0eeWd1H3SO0ztmcOz7LnPKY0/9EXUJcMxQvke0fP86w+Vt390HMzievwR+0jPv89o6HjmU/ibquWmTNr1Ty3fwUL4PUX90pzN90jTrPA84aIL02/YJ9R6NAjxtJb7PEx7/zvyLgG9OMi/Uiw1vov7AXa3vcoc+vztwK3CXafLvy/I6o/v6TCfPJ6k/xO8y9NmjgJOnWPYane/eAzvpxzLx+WlfJvj/nuL/5qTBcZ9JWVfl2PryNaqXkavmTaktDg+kNg+/k3pF6unAkUnePMFHXkU9Mb+ylLLP0LydqZX3oandjdZoVwq/3eY/sv09llpJDUYGeQz1KvJ3h9IuKqX8aobLfjjwu9LpR1zqFbEv9NgdfQwut5VJ5h8PbNS6SDxluJtET1+ZQd5DS6erWSnlR9QrjLcbMWoWDfb1Z4bSB9OPGko/Ymj6tPb37u3vjPdZkvWABwGfL52WoFLKucCPJijDbJvtfbAyZmuZ96K2YBzSTSyl/BA4n5nvy7OBPwIfS+0WteUMP9/HztSy/XiC88HgpuuubwxNn0bt1rhpmz4eeECS/0ryuCTrrmS5Lgd+A/x7khcl2XYllzOR0DnvJNksyceSnE89N95EDZY3pB7PqReW3Cm1C9ivqV15bqLeAxSgb7l3oLYUD15v6czbmfod/dPQMToSuH+SO7VyrJXkjaldU//cyvGDtox7Mfu+WkoZPn/3Kesoj620UgwgNK9KKbeUUr5fSnlzKeVx1Cbk04B9uv1Qm92AC6ndl4ZtAqxFHcnpps7r0jb/Lm19VwKnAI9Oclfq1dxj2munlvfRbXpGy6beAHvJBGWbKG1lbEmtrK+YaGYp5XvAP7R8XwEuS/KdJPebwTpmMtrRZNu6+QyWMVODbh3D5bx4aP7A8L66of29A6z0PtuI+kNnon118QRl6GMwesw9euSd1X2wkmZrmZNtC6zEviyl/In6//t74MPAb1v//GdO/Ul+R799D/V8cA9WPBfcRO02BcvPBwPT7atPUbulPIz6o/GK1Hu7tupZHuC2e6UeT20dezdwVuvT/88zWc6wdl/CXWnHKPU+j8OoXUHfQb3g8hDqRSDo9x34X+Cl1K6Dj2+ff/kMPg9wYinlhM7r3M68TYA9uP0xel+bPzhG76a2InyGOvrfQ1ne5XRV/j8mM9H3fNqyjurYSqvCeyC0oJRSfp96k/P+1CtRx3VmPxP4OHBskseUUro3YF9O7Rbwd5Ms+ved98dQ+48/un3uVOqJfZMkg6EyP9bJ33fZF1H78g7bdIK0GWn3VzwO+GmZYuSRUsqh1JaS9akB0XuAbyXZokw/ChBM3roxkYm2a1NqS9LADdTgq2v4B9ZMDH6M3Y0V7ye429D83lZin11J3U93m2De3VamDNThW99Jvc/m/dPknfV9MCJ9jn13W4bdDThxhsujlHIy8Mx2FXd76n0VX0hy/1LK6ZOU9TvA45M8uJRy4iR5Bi4HzqWeQyZy3jSfHy5voZ5vPtYumjyB+h34PDWogHr+WWHbk0y07b8B9ki9OeD+wCuADyc5r5TyzZmUq+OJ1K5mP2zT21D36/NKKbe1giV5ap+FpQ48sSu169X+nfS/WcnyTeRyakvCeyaZPzhn7wZ8qpTyjk451p/Beq5vn1mrlHJjJ32yc9xE59deZR3RsZVWmi0QmjdTdC/Yrv0dHqHpQuoPvNWoQ1t2R2n5FvWK0QZDV6UGr24A8V1gC+oNcceW6lLqvQpvo1aWx6zEsn8CbJnkti4M7WrdZD80emkVxnupV6o+2OczpZRrSimHU3+YbMbyCu0G6k2as+FZWXHUmR2p+/UnnTznU1t5up48wbL6luv77e/wjZbPbX+P7bGMCU2xz4bzXUv9YfsPWXHUmXtQb9adcRlKKcdRv5dvzCQPw0oyGMZ1FPvgRmbvezHQ59ifSW21WmFbkvwt9Sr/sTNc3m1KKTe37oRvoZ4z7j1ZXuAT1HuwPtS6qK0gddSlx7XJb1FbrK6Z5HzwhynWM6VSypWllM9Tuz12t3Wm215aIPXqljT82V5SHyL3XurFkc+15EEXq5s6+dZk+feva6Lv1drUc+zwQAt7rkwZJ/Et6o3ov5jkGA1agdadoBx7TbC8yc5P57e/t+3f1g1yJkP+9i0rMHvHVlpVtkBoPp2e5Bhq15FzgTtRR5V4KfCFUspvhz9QSrkoyU7UH1vHtJaI35dSjk3yWeqV5A9QWy5upd68tgvw+rJ8lKcfUEdBeSzLm82hBg2vAH5bOuPfz2DZB1NHIPlykjdSuzi9tG1XX2t1ApB1Wf4guYdTb0ac9EnGSfajtgAcQ71qtQV1FKCTS32eAtQbn1+W5B+pV6+vLqWcOYPydd0R+GqSj1FHX3k3tQ/6pzp5Pge8OcmbgJ9SW3GeM7ygvuUqpZzejsW+7Qrzj6n75i3AZ0sppw1/Zio999lE3kLt23546hCh61ODzz8xfQvCZHanXgk/Psl/sfxBcttRRztakzpa2azug+YM4MlJvkVtYfn9UNC9MqY99qWUW5K8lXr1/TPUriSbU1tjzmbFB3dNu7wkT6GOcPNV6jllPerxvJoVA9sVlFKuaN2cDgNOavt/8CC5h1L/jw+lHp9DqD8yj059PsQp1NaBbagPgfz7MoPnJST5eKd8l1IHl3gey++xGmz7gUk+SB3R6f4M/eBu3e72p7ZcnEP9kb4ndQSlPg9y27yde1ajdh3bgTowRICnllL+3PL9kvrD+Z1JbqH+AJ/sAXsTfq+S/BR4TZKLqIHb85ndro9vpZ6nv5/kQ9RWoY2oP7bvWUoZPFX6W9SRAE+j7rNnMPGP/8nOT9+k/s//T5J9qMHR64DeI4f1KessHFtp9pUFcCe3r/F8USvlw6iV0fXUewx+Tj0Br9XJtydtFKZO2ibUeyXOAjZvaatRh149pS3vT+39e6mtB911/4zOSEstbTBC00ETlLXXsqn3cBwBXEcdWWN/aktHod8oTIMRRW6l/qj4JXWUjh0myL9nd7nUK5JHUq8W3kDt1/1JVhwZ526tfFfTGU1non08VK7zOtNbtbwvAz7QtvM66g/qrYc+e4e2Dy5q6/w89QfZbSPn9CzXVp28a1H7Xp9P/fFyfptec4IyvnCoPDu19J367rMpjtfO1B99f27fh68B9xrK02sUpk7+9anDSP6c+v9wA/Uq/f7UHxOzvg9a2o7UVpXrWXFkn8mOfZ9l9jr2Le/u1P+nG6hdOj4NbDbT7xI14P48NXi4nvrdPAJ4WM/9fw/qqEiDm3uvod7kvDdwp6Gy7Av8quW7ouXblzYyV2efPG6a/9tl1JaWS9uyzqW2NHbXtxr1h+b51P+1I6kBS/dYbUK9iHFWy3MF8D3giT22uzua0U3UH/U/pI7stfEE+R/Q5l9HHThhP+qzNIb/Vyf7Xm1F/fF9ddvuD1H/F1f4Dk1S1n1bvjWmybcFtWXpQmogfhF1ZKPdO3nuSg3OrmyvQ6j3Y/Q6P7V5j2jH/rq273en5/9N37KuyrH15WtUr8EwcpIkSZI0Le+BkCRJktSbAYQkSZKk3gwgJEmSJPVmACFJkiSpNwMISZIkSb0ZQEiSJEnqzQBCkiRJUm8GEJIkSZJ6M4CQJEmS1JsBhCaU5KAkh8/CcvZNcvpslGma9WyVpCTZftTrGndJ9kxyzYiWfWySD3Wmz0vy2hGta2TbIY2DuawnZmtdGp1R1vfDdUGr7581onXNye+Wxc4AYhFoJ85953i1rwR275RhhR92C9DvgM2Ak/t+IMlOSc6bJs957UTVff1xFcs6vI5537dtXwy279YkVyU5Ncn+SbYeyv554J49lzvTwO4ZwBtmUvae5Ziosum9HdJCZz0xe9rFhWOnyTNcL5QkveufnuUY2QWUGZRhz8723ZLkj0lOSPLOJJsMZf8P4FE9lzuoc+7asygPAT48k7L3KMNk9VPv7Rhna8x3AbQwlVL+NN9lmIlSyi3AxSNa/H7ARzrTt45oPassyZqllJtWYRF/DVwBrA/cH3gVcFqSJ5dSvgdQSvkz8OdVLmxHkrVKKTeWUq6YzeVOZRTbIY2TxVZPjMCLgG6ryKqce0cmyWpAWj25Mq4DtgEC3In6Y/71wIuSPKqU8kuAUso1wKy26nbqhstmc7lTGcV2LEW2QCxCSdZK8q4k5ye5Iclvkvxrm7d6kk8mOTfJn5OcneR17QQy+PxBSQ5P8uYklyS5Jsn/JllnOM/gPTUaf3nnSsRWfdbVc3vWS/KpVo5Lkryhle+gTp7dkxyf5Ooklyb5YpLNO/NXuJLQubrx2CQ/S3Jdu2ryoJXY5VeXUi7uvC7trHeDJB9vZbo6yfe6VzOS3CXJZ5Nc0PbRL5Ls1Zk/2b693dWZKbZxlyTHJbkReGKb99QkJya5vh2fdyZZq8e2Xtq28ZxSypeAnYCfAwcmWb0te4WuP0m2TPK1JFe0/fyrJLu12ee2v8e3sh472O52jF+f5ALggpY+0RXM9ZN8pn0/Ls7QFblM0LqQzpW7LG9l+mLLe95E29HSXpLknCQ3tr8vmmBdL27fv2vb/97uSAtMllg9McH2rZ3kP1vZrk/y0ySP6MxfM8kBSX7ftv93Sf69M/8Zqa2sf27nru8l2XSGxfjjUN1weWf5myf5XJIr2+sbSbbtzN+mnTcvbueSk5I8pTP/WOAewPsG+7OlT3TeWqG+GORpdcPpwI3Avdu8vZKc0fbZWUn+rcexKG37LiqlnFlK+QzwcOCPwEc75Vih60+Sv0lydGqL9jVJTkny6CRbAce0bJe1sh802O4kH0nyH0kuA37U0idqjblb26/Xte95tzVswtaFrFhfTFY/DW/Hakne0r5DNyQ5LcmuE6zrmUmOauU5I8njp9mvi5oBxOJ0MLAH8GrqSeEF1H9kqMf0QuDZbd6bgDcCew0t41HUK8yPBZ4JPAF4zyTreyXwE+B/qd2ENqN2Geq7rum8v5Xn6cBjWrn+bijPWsA+bd5TgLsCn+2x7HcDewMPAi4HDkmSGZZvQm053wA2b2V6IPB94LtJNmvZ7gCc1Ob/NbA/8LEkj23zJ9u3M/Ee4M3AdsDPkjwROAT4UFvn84FnAe+a6Ta2K1YfpHb1eeAk2T4MrAs8uq3vVSz/Pj60/d2Zum3P6HzuUcD92rzHMrlXA7+kHsN9gHclecYU+Yc9pP19USvDQybKlOTp1H32n8B9qcfqw0meOpT1rcDXqN/Fz1ODq7vPoDzSXFhq9cSw9wL/SD2/PRA4DfhW59z7r9Q6ZTdg25b3TIAkdwM+R91H9wYeCXx6FctzmyTrUn8gX0/dhw8HLgK+0+ZBbeX9JvB46j7+EvDlJNu1+c+gXljZj+X7cybuALwFeAlwH+D81Asi76Kew+4NvIbakvCymW5ju0r/UeCRSTaeJNv/Ubf7ocADgH2p++R31O8T1DpjM+r3Z2B3amvH31G/w5N5G3BYW/bHgU8NBwzTmKp+6nol8P+o++pvgK9Qj9UDhvK9EziAejyPBz6XZP0ZlGdxKaX4WkQv6omwADvP4DP/DnynM30QtSJZv5O2O3ADsF4nz+Gd+ccCH1qJde0LnD5F/vWpV0d266StB1wJHDTF57Zr+2GLNr1Vm96+Te/Upp/Y+cyO3c/03Hfntf1yTef1xjbvMW16naHPnAy8boplfg74xFT7tlP+u3bSJtvGZw599vvAW4bS/r6VNZOU6Xbrm2BfP7tN7wlc05l/KrDPJMtdocxD38HLgLWH0lfYF23/HzWU5xPADzvTBXjWBMfttdPkGd6OHwEHTlDO4XW9uzO9BrV5f/e+3ylfvkb9YonVE8ProtYRNwJ7dOavDvwaeEebPgA4eqJzHvViRAHusQr7uFC7QHbrhue2ec8Hzu6uu5Xv8sF5dJJl/hR4c2d6hfNYS1vhvNXSdqJz/m55CvDgoXy/BZ43lPYq4IwpynS79XXm7dzW89CJjiNwFbBsks+uUOah79CpE+RfYV+0z/7PUJ7vAJ9p77di4rrntrpgijzD23Eh8NYJyjm8rpd05m/e0h6xst+xhf7yHojF54HUPvjHTJYhyUuBF1KbP9cB1gTOH8p2aqlXEAZ+Qr3Kvw31B2EvPdc1yPt31CsuAy8BTm+fOW6QWEq5NkMjIKR2PdqHeqXhztSrEwB3p3V/mUR3W37f/m4yzWeGfQD4ZGd60E//wdQr75cNNWrcgbofSe32szf16tfmwNrU/XzsDNY/nROGph8MPDTJ6ztpq1GPz92oV4RmYrBxZZL5+wMfTbIztcL+SinlxB7LPb2UckOPfD+ZYHomLRB93Rs4cCjth8DThtJu+06VUm5uzezDNxNK82lJ1ROllEOGsm3TlvGjQUIp5ZYkP6FebYcacBwFnJXk28ARwDdLKbcCp1B/bJ7e5n0HOLTMvJ/9/wO+1Zm+pP19MLA1cPVQ3bAuy+uG9ah12lOoV7/XpNYdvffrNG6mM6hIayXYktoC3r2nbw2Wn+Nnarq64QPAJ5Iso9YNXyql/KrHcvvUHzBx3fDknp/tJcmdgL+g811rfgjsMpQ22e+NJckAYolJ8o/ULhivBX5MvQLwcmpT7nyv6wRqADBwCT1GwWkn2iOpJ/nnAZdSuzD9gFqZTaV7U9vgJDfTrnuXl1LOmSB9Neo2DHe3grovoO6b11CbQE+jXqV6F9OfVAY3andP7GtOkvfaCcr1NuCLE+RdmRvRBhXybyaaWUr5ZJIjqSfTxwE/TvLuUsq+0yx3uNwrq3D7CnCyfbWyy+8avlGyYHdQLSKLsJ6YiXqZuZSTWl/7J1K7YB0MnJLk8S3YeAKwA7Vb1guAd6feEHzKDNZ18RR1w8nU7lPDBheg/oN6Bf+11NaK64BPMX2ddiv9znc3lBVvmh6co15KPQ6z4T7U/X3eRDNLKfsmOQR4EvU47JPkpaWU4Qs1w2ajbrhdHZpkNusFmKJuKKWUFjwu2brBAGLxOZn6hXw0K175GHgE8LNSSncs/W0myPc3SdYrpQz+UXegNgn/epL13khtgl2ZdQG3jXqzwsk2ya+p/3QPof1AbX1E79spy3bUgOGNpZRzW55RXIGeqZOATYFbSykT/rim7qOvl1I+DbfdN/FXLO+LDBPv28EP/c0674f7W05Vru0mqdhmpLWgvIp6LCYdorCUcgG1D+rHW8vHK6nNwDe2LMPbNxM7TDD9y870ZXT6B6feCDncX/imHmX4JbWbW7e16RHAGTMprLQALKl6YgK/buvacVCWdq56OLXf/WBZVwOHAoe2m3R/CvwlcFap/Ux+AvwkyX7AL6gtxTMJICZzEvAc4A+llMmG/X4E8KlSB6sgyaDl+qxOnsnqhnWT3KmUMrhQNW3dUEq5JMnvgW1KKZ/qvykTa337Xwp8b6qWm1LK2dQA6YDW8vFCakvvbNUNBw5ND+qGbh06MLyfpi1DKeWqtt92pLaiDIx93WAAsciUUs5K8gVqs+ArqSeqLYCt2o/Us4A9kzyJehLejXoT15VDi1qDevPnftTmuX+n9iecLPI/j9otZivqVfQrZrCuqbbnmiQHAu9J8gdq95o3Uyu/QXT/W2q/21ck+W9qV5O3913HCH2H2qz5tSSvA35F7SK0M7V/7w+o++gfU0cH+QPwL9Sm7Z93lnMet9+351BvNNs3yd7UPpZv7lmu/YDDk5wPfIHalH1faj/V103z2U2SrEG9N+V+wL9Ru0PsUiYZAjDJ/tQuB2dRh/jbmeUn1kup/YSfmDr60fVl5kM/7pDkDdQfAjtRb6p7bmf+d6kjv/wYuIXawnP90DLOAx6b5HvUK3MTfUffRx2p6UTg2207nstouktJI7PU6okJtu/a9mN0UG+cSz1XbUp7VkCSV1Prk5OpFxD+idr6cUGSHaitpUdSWzgeSO3eM1s/CA+htix8LclbqXXYlsCuwEfbj+qzgKcn+Vor3z7ULkxd5wF/l+Qz1PPWH4CfUa/QvzvJB6k37Pa9CXof4L9Sn2V0BLXl4kHA5qWUd0/xubQbzwE2YPkwrhtw+y6egw+sQ21l+WLbjk1pwWTLcj61jn9ykq8Dfx7qLtfHM5IcT+0S/CxqS9PDoAaiSX4KvL5dqNyAOqhKV9/66X3AfknOpnav2p3a82BlRnVcMpZs08oStwf1KssB1B+tB1H/OQA+Rv3R+H/UUQC2oo5yNOx71Csux1BHFPguMNWPy/+gRutnUCP7u89gXdN5LbU70mGtPKdSm7GvB2hXN5ZRbwQ+g3oSfPVKrGdWtStYu1D33f9QR/j4AnAvlvd/fAf1/o5vUm9uvpZauXTdbt+W+iyH3ahdvE6hdkl6Y89yHUntB/rotu7jqPdh/LbHx39BrXR/Tg1Efg7cr5Ty/Sk+sxrwX6147sL2AAAgAElEQVT8R1Er5GWtLDdTR0N5IXWffK3PNgz5ADWY+Tl1f761lHJoZ/5rqK1Xx1KDjE9QKwaG8jyaGpT9nAmUUr5KDfD+rW3LK4GXlVK+vhJllubbUqsnhr2eOgra/1KDhPtRbxof3ON1NfUeheOoAdQDgCeVUq4D/kS9onw49er4+4G3lzo86Spr63gk9bz0Rer+PxjYiOWB06up56kfUOuHn7b3XW+lBh6/pl1RL/VZOc+ljt50GvBi6mhLfcr1CeoN3s+j1is/aJ8/d5qPrkutF35P3Z+vBr4O3Le0Z0BM4Bbq9h5ErRu/Qm3xeXUry4XUuvyd1DpjZR5AuC91NKdTgX8G9iqlHN+Z//z293jq93CFi3AzqJ8OoAYR76Xet/l06uAls9FatWil/gbSOGlNuXctpTxlurzzIcna1KsT7yulzEZFI0magYVeT0iaX3Zh0rxL8kBqt6TjgDtSryzdkXp1SZIkSQvIvHVhSnJIkjOTnJ7kwMHd8akOSH0K7KnpPDk4ybLUp1ie3YYFG6Q/OPXJgOe0z87Kg8I0p15N7VryXWpfyUe2G3MljRnrB0la2EbWhSnJRpPcqDiYvwvLx3r+P+D7pZSPtPR/ofYtfxiwfynlYUnuTO0Xvz31xpsTqQ9JuTLJcdR+bD+j3hh0QCnlm0iSFhzrB0la3EbZAnFCu4r0mImu+JRSjigNtevKFm3WrtShzUop5afAhqmPpn8i9Ym0V7SK5yhg5zbvTqWUn7ZlfYp6s60kaWGyfpCkRWyU90D8FfXhIa8A/jvJp4GDSim/72ZqTdPPo454AvVpvb/rZLmgpU2VfsEE6beT5MXUEQdYb731HrzddtvNeKNOvPzyGeV/8F3uMuN1SNIonXjiiX8opWw8j0VYUPXDbNQNYP0gafHrWz+MLIBoY8YfTh2PfmPq+Lu/TfK3pZTjOlk/TG2eHh6+bBRl+jj1YVdsv/325YQTTpjxMnLwwTPKf8KyZdNnkqQ51J4RMm8WWv0wG3UDWD9IWvz61g8jvYk6yQZJXkId339b6pi8p3bm7wNszIpj+l9IHfd4YIuWNlX6FhOkS5IWKOsHSVq8RhZAtCcnnkR96u4epZRHlVI+VUq5vs1/IbXf6nNKKbd2PnoYsEcbbWMH4E/twTBHAk9IslGSjYAnAEe2eVcl2aH1pd2DlXtYlSRpDlg/SNLiNsp7IL4A7Nme9DeRj1IfFvaTdg/dl0sp+1FHydiF+sj764C9oD59McnbqU8UBNivPZER6mPcDwLWoY7c4QgbkrRwWT9I0iI2ynsgDptm/oTrbiNlvHySeQcCB06QfgJw35UopiRpjlk/SNLiNm8PkpMkSZK0+BhASJIkSerNAEKSJElSbwYQkiRJknozgJAkSZLUmwGEJEmSpN4MICRJkiT1ZgAhSZIkqTcDCEmSJEm9GUBIkiRJ6s0AQpIkSVJvBhCSJEmSejOAkCRJktSbAYQkSZKk3gwgJEmSJPVmACFJkiSpNwMISZIkSb0ZQEiSJEnqzQBCkiRJUm8GEJIkSZJ6M4CQJEmS1JsBhCRJkqTeDCAkSZIk9WYAIUmSJKk3AwhJkiRJvRlASJIkSerNAEKSJElSbwYQkiRJknozgJAkSZLUmwGEJEmSpN4MICRJkiT1ZgAhSZIkqTcDCEmSJEm9GUBIkiRJ6s0AQpIkSVJvBhCSJEmSejOAkCRJktSbAYQkSZKk3gwgJEmSJPVmACFJkiSpNwMISZIkSb0ZQEiSJEnqzQBCkiRJUm8GEJIkSZJ6M4CQJEmS1JsBhCRJkqTeDCAkSZIk9WYAIUmSJKk3AwhJkiRJvRlASJIkSerNAEKSJElSbwYQkiRJknozgJAkSZLUmwGEJEmSpN4MICRJkiT1ZgAhSZIkqTcDCEmSJEm9GUBIkiRJ6s0AQpIkSVJvBhCSJEmSejOAkCRJktSbAYQkSZKk3gwgJEmSJPU2bwFEkgOTXJrk9E7avkkuTHJye+3SmfeGJOckOTPJEzvpO7e0c5LsPdfbIUmaXdYPkrSwzWcLxEHAzhOkf7CU8oD2OgIgyX2A3YC/bp/5cJLVk6wO/DfwJOA+wHNaXknS4nUQ1g+StGCtMV8rLqV8P8lWPbPvCnyulHIDcG6Sc4CHtnnnlFJ+A5Dkcy3vGbNcXEnSHLF+kKSFbd4CiCm8IskewAnAa0opVwKbAz/t5LmgpQH8bij9YXNSyp5y8MG985Zly0ZYEkla9JZU/SBJi9VCu4n6I8A2wAOAi4D3z+bCk7w4yQlJTrjssstmc9GSpNEaWf1g3SBJM7OgAohSyiWllFtKKbcC/8PyZugLgS07WbdoaZOlT7b8j5dSti+lbL/xxhvPbuElSSMzyvrBukGSZmZBBRBJNutMPh0YjMBxGLBbkrWTbA1sCxwHHA9sm2TrJGtRb6Q7bC7LLEkaPesHSVo45u0eiCSfBXYC7prkAmAfYKckDwAKcB7wEoBSyi+SfIF689vNwMtLKbe05bwCOBJYHTiwlPKLOd4USdIssn6QpIVtPkdhes4EyZ+cIv87gXdOkH4EcMQsFk2SNI+sHyRpYVtQXZgkSZIkLWwGEJIkSZJ6M4CQJEmS1JsBhCRJkqTeDCAkSZIk9WYAIUmSJKk3AwhJkiRJvRlASJIkSerNAEKSJElSbwYQkiRJknozgJAkSZLUmwGEJEmSpN4MICRJkiT1ZgAhSZIkqTcDCEmSJEm9GUBIkiRJ6s0AQpIkSVJvBhCSJEmSejOAkCRJktSbAYQkSZKk3gwgJEmSJPU2bQCRZMck67X3uyf5QJJ7jL5okqSFzPpBksZTnxaIjwDXJbk/8DrgfOBTIy2VJGkxsH6QpDHUJ4C4uZRSgF2B/Usp+wN3HG2xJEmLgPWDJI2hNXrkuTrJG4DdgUcmWQ1Yc7TFkiQtAtYPkjSG+rRA/CNwA/CCUsrFwBbA+0ZaKknSYmD9IEljaNoWiFYpfKAz/Vvs4ypJY8/6QZLG06QBRJKrgTLZ/FLKnUZSIknSgmb9IEnjbdIAopRyR4Ak+wEXA58GAjwXb5KTpLFl/SBJ463PPRBPLKV8uJRydSnlqlLKR4BnjrpgkqQFz/pBksZQnwDiliTPTbJ6ktWSPBe4ZdQFkyQteNYPkjSG+gQQ/wQ8G7ikvf6hpUmSxpv1gySNoSlHYUqyOvD0Usquc1QeSdIiYP0gSeNryhaIUsot1CeMSpJ0G+sHSRpffZ5E/aMkHwI+D1w7SCylnDSyUkmSFgPrB0kaQ30CiL9tf/frpBXgMbNfHEnSImL9IEljqM+TqB89FwWRJC0u1g+SNJ6mHYUpyQZJPpDkhPZ6f5IN5qJwkqSFy/pBksZTn2FcDwSupg7V92zgKuB/R1koSdKiYP0gSWOozz0Q25RSuk8WfVuSk0dVIEnSomH9IEljqE8LxJ+TPGIwkWRH4M+jK5IkaZGwfpCkMdSnBeKfgYM7/VqvBPYcWYkkSYuF9YMkjaE+ozCdDNw/yZ3a9FUjL5UkacGzfpCk8dRnFKZ3JdmwlHJVKeWqJBslecdcFE6StHBZP0jSeOpzD8STSil/HEyUUq4EdhldkSRJi4T1gySNoT4BxOpJ1h5MJFkHWHuK/JKk8WD9IEljqM9N1IcARycZjO29F3Dw6IokSVokrB8kaQz1uYn6PUlOAR7Xkt5eSjlytMWSJC101g+SNJ76tEAA/BK4uZTynSTrJrljKeXqURZMkrQoWD9I0pjpMwrTi4BDgY+1pM2Br46yUJKkhc/6QZLGU5+bqF8O7AhcBVBKORvYZJSFkiQtCtYPkjSG+gQQN5RSbhxMJFkDKKMrkiRpkbB+kKQx1CeA+F6SNwLrJHk88EXg66MtliRpEbB+kKQx1CeA2Bu4DDgNeAlwBPDmURZKkrQoWD9I0hjqM4zrrcD/tBcASXYEfjTCckmSFjjrB0kaT5MGEElWB55NHVXjW6WU05M8BXgjsA7wwLkpoiRpIbF+kKTxNlULxCeBLYHjgAOSnA88HNi7lOIwfZI0vqwfJGmMTRVAbA/cr5Rya5I7AH8AtimlXDI3RZMkLVDWD5I0xqa6ifrG1r+VUsr1wFlWDpIkrB8kaaxN1QKxXZJT2/sA27TpAKWUcr+Rl06StBBZP0jSGJsqgLj3nJVCkrSYWD9I0hibNIAopZw/lwWRJC0O1g+SNN76PEhOkiRJkgADCEmSJEkzMGkAkeTo9vc9o1p5kgOTXJrk9E7anZMcleTs9nejlp4kByQ5J8mpSR7U+cyylv/sJMtGVV5J0ujrB+sGSVrYpmqB2CzJo4CnJXlgkgd1X7O0/oOAnYfS9gaOLqVsCxzdpgGeBGzbXi8GPgK1UgH2AR4GPBTYZ1CxSJJGYtT1w0FYN0jSgjXVKExvpZ6gtwA+MDSvAI9Z1ZWXUr6fZKuh5F2Bndr7g4Fjgde39E+VUgrw0yQbJtms5T2qlHIFQJKjqBXPZ1e1fJKkCY20frBukKSFbapRmA4FDk3yllLK2+ewTJuWUi5q7y8GNm3vNwd+18l3QUubLF2SNALzVD9YN0jSAjFVCwQApZS3J3ka8MiWdGwp5fDRFuu2dZckZbaWl+TF1CZu7n73u8/WYiVpLM1X/WDdIEnza9pRmJK8G3glcEZ7vTLJu0ZYpkta8zPt76Ut/UJgy06+LVraZOm3U0r5eCll+1LK9htvvPGsF1ySxskc1w/WDZK0QPQZxvXJwONLKQeWUg6k9iF9ygjLdBgwGC1jGfC1TvoebcSNHYA/tebsI4EnJNmo3SD3hJYmSRqtuawfrBskaYGYtgtTsyFwRXu/wWytPMlnqTe63TXJBdQRM/4d+EKSFwDnA89u2Y8AdgHOAa4D9gIopVyR5O3A8S3ffoOb5iRJIzfr9YN1gyQtbH0CiHcDP09yDBBqX9e9p/5IP6WU50wy67ET5C3AyydZzoHAgbNRJklSbyOpH6wbJGlh63MT9WeTHAs8pCW9vpRy8UhLJUla8KwfJGk89erC1PqTHjbiskiSFhnrB0kaP31uopYkSZIkwABCkiRJ0gxMGUAkWT3J6XNVGEnS4mD9IEnja8oAopRyC3BKEh/NKUm6jfWDJI2vPjdRbwb8IslxwLWDxFLK00ZWKknSYmD9IEljqE8A8baRl0KStBhZP0jSGOrzHIjvJbkHsG0p5TtJ1gVWH33RJEkLmfWDJI2naUdhSvIi4FDgYy1pc+CroyyUJGnhs36QpPHUZxjXlwM7AlcBlFLOBjYZZaEkSYuC9YMkjaE+AcQNpZQbBxNJ1gDK6IokSVokrB8kaQz1CSC+l+SNwDpJHg98Efj6aIslSVoErB8kaQz1CSD2Bi4DTgNeAhwBvHmUhZIkLQrWD5I0hvqMwnRrkoOBn1Gbps8spdhELUljzvpBksbTtAFEkicDHwV+DQTYOslLSinfHHXhJEkLl/WDJI2nPg+Sez/w6FLKOQBJtgG+AVhBSNJ4s36QpDHU5x6ISweVQ/Mb4NIRlUeStHhYP0jSGJq0BSLJM9rbXyQ5AvgCtY/rPwDHz0HZJEkLkPWDJI23qbowPbXz/hLgUe39ZcBGIyuRJGmhs36QpDE2aQBRStlrLgsiSVocrB8kabz1GYVpa+BfgK26+UspTxtdsSRJC531gySNpz6jMH0V+CT16aK3jrY4kqRFxPpBksZQnwDi+lLKASMviSRpsbF+kKQx1CeA2D/JPsC3gRsGiaWUk0ZWKknSYmD9IEljqE8A8TfA84DHsLyJurRpSdL4sn6QpDHUJ4B4OnDPUsqNoy6MJGlRsX6QpDHU50nUpwAbjrogkqRFx/pBksZQnxaITYFfJTmeFfu4OkyfJI036wdJGkN9Aoh9Rl4KSdJiZP0gSWNo2gCilPK9uSiIJGlxsX6QpPHU50nUV1NH1QBYC1gTuLaUcqdRFkyStLBZP0jSeOrTAnHHwfskAXYFHjrKQkmSFj7rB0kaT31GYbpNqb6KY3xLkjqsHyRpfPTpwvSMzuRqwPYsb7KWJI0p6wdJGk99RmF6auf9zcB51GZqSdJ4s36QpDHU5x6IveaiIJKkxcX6QZLG06QBRJK3TvG5Ukp5+wjKI0la4KwfJGm8TdUCce0EaesBLwDuAlhBSNJ4sn6QpDE2aQBRSnn/4H2SOwKvBPYCPge8f7LPSZKWNusHSRpvU94DkeTOwKuB5wIHAw8qpVw5FwWTJC1c1g+SNL6mugfifcAzgI8Df1NKuWbOSiVJWrCsHyRpvE3VAvEa4AbgzcCb6kNGAQj1Jrk7jbhskqSFyfpBYyEHH9w7b1m2bIQlkRaWqe6BmNFTqiVJ48H6QZLGm5WAJEmSpN4MICRJkiT1ZgAhSZIkqbcph3HVwjaTm7vAG7wkSZK06myBkCRJktSbAYQkSZKk3gwgJEmSJPVmACFJkiSpNwMISZIkSb0ZQEiSJEnqzQBCkiRJUm8GEJIkSZJ6M4CQJEmS1JsBhCRJkqTeDCAkSZIk9WYAIUmSJKk3AwhJkiRJvRlASJIkSerNAEKSJElSbwYQkiRJknpbsAFEkvOSnJbk5CQntLQ7Jzkqydnt70YtPUkOSHJOklOTPGh+Sy9JGgXrBkmafws2gGgeXUp5QCll+za9N3B0KWVb4Og2DfAkYNv2ejHwkTkvqSRprlg3SNI8WugBxLBdgYPb+4OBv++kf6pUPwU2TLLZfBRQkjTnrBskaQ4t5ACiAN9OcmKSF7e0TUspF7X3FwObtvebA7/rfPaClraCJC9OckKSEy677LJRlVuSNDrWDZI0z9aY7wJM4RGllAuTbAIcleRX3ZmllJKkzGSBpZSPAx8H2H777Wf0WUnSgmDdIEnzbMG2QJRSLmx/LwW+AjwUuGTQ/Nz+XtqyXwhs2fn4Fi1NkrSEWDdI0vxbkAFEkvWS3HHwHngCcDpwGLCsZVsGfK29PwzYo424sQPwp05ztiRpCbBukKSFYaF2YdoU+EoSqGX8v1LKt5IcD3whyQuA84Fnt/xHALsA5wDXAXvNfZElSSNm3SBJC8CCDCBKKb8B7j9B+uXAYydIL8DL56BokqR5Yt0gSQvDguzCJEmSJGlhMoCQJEmS1NuC7MIkSZI023LwwdNnkjQtWyAkSZIk9WYLhCRJ0iqaaetGWbZs+kzSAmULhCRJkqTeDCAkSZIk9WYAIUmSJKk3AwhJkiRJvRlASJIkSerNAEKSJElSbwYQkiRJknozgJAkSZLUmwGEJEmSpN4MICRJkiT1ZgAhSZIkqTcDCEmSJEm9GUBIkiRJ6s0AQpIkSVJvBhCSJEmSejOAkCRJktSbAYQkSZKk3gwgJEmSJPVmACFJkiSpNwMISZIkSb0ZQEiSJEnqzQBCkiRJUm8GEJIkSZJ6M4CQJEmS1JsBhCRJkqTeDCAkSZIk9WYAIUmSJKk3AwhJkiRJvRlASJIkSeptjfkugCSpysEHzyh/WbZsRCWRJGlytkBIkiRJ6s0AQpIkSVJvBhCSJEmSevMeiAVkpv2fJUmSpLlmC4QkSZKk3gwgJEmSJPVmACFJkiSpN++BkCRJi5L3DkrzwxYISZIkSb0ZQEiSJEnqzQBCkiRJUm8GEJIkSZJ6M4CQJEmS1JujMEmSJC1wMxlxqixbNsKSSLZASJIkSZoBWyAkSZLmmM+w0GJmC4QkSZKk3gwgJEmSJPVmACFJkiSpNwMISZIkSb0ZQEiSJEnqzVGYNCtmOpqEY1RLkiQtTrZASJIkSerNAEKSJElSb3ZhkiRJWkLsVqxRM4DQhHxCpiRJkiZiFyZJkiRJvRlASJIkSeptyXRhSrIzsD+wOvCJUsq/z3ORJEkLgPXD4mIXWmnhWxIBRJLVgf8GHg9cAByf5LBSyhnzWzJJ0nwa1/rBm2gljdKSCCCAhwLnlFJ+A5Dkc8CuwJKuICRJ01qw9cNMfuQv5h/4tigsPePy3dXklkoAsTnwu870BcDD5qksmmWjvpLmiVBa0qwfZpkBgWZiMbeGLeayj1pKKfNdhlWW5FnAzqWUF7bp5wEPK6W8Yijfi4EXt8l7AWeuxOruCvxhFYq7WIzLdsL4bKvbufSs7Lbeo5Sy8WwXZiHqUz/MUt0A4/Xdm477Yjn3xXLui+UW6r7oVT8slRaIC4EtO9NbtLQVlFI+Dnx8VVaU5IRSyvarsozFYFy2E8ZnW93OpWectnUVTFs/zEbdAB6PLvfFcu6L5dwXyy32fbFUhnE9Htg2ydZJ1gJ2Aw6b5zJJkuaf9YMkzbIl0QJRSrk5ySuAI6nD9B1YSvnFPBdLkjTPrB8kafYtiQACoJRyBHDEHKxqlZu5F4lx2U4Yn211O5eecdrWlWb9MC/cF8u5L5ZzXyy3qPfFkriJWpIkSdLcWCr3QEiSJEmaAwYQM5Bk5yRnJjknyd7zXZ4+kmyZ5JgkZyT5RZJXtvQ7Jzkqydnt70YtPUkOaNt4apIHdZa1rOU/O8myTvqDk5zWPnNAksz9lt5WltWT/DzJ4W166yQ/a2X7fLuJkiRrt+lz2vytOst4Q0s/M8kTO+kL4vgn2TDJoUl+leSXSR6+FI9nkn9r39nTk3w2yR2WyvFMcmCSS5Oc3kkb+TGcbB1adQvl/DBKo/7eLhaZg3p1sWjn5eOSnNL2xdta+qydqxebjPB3yIJSSvHV40W9+e7XwD2BtYBTgPvMd7l6lHsz4EHt/R2Bs4D7AO8F9m7pewPvae93Ab4JBNgB+FlLvzPwm/Z3o/Z+ozbvuJY37bNPmsftfTXwf8DhbfoLwG7t/UeBf27vXwZ8tL3fDfh8e3+fdmzXBrZux3z1hXT8gYOBF7b3awEbLrXjSX3417nAOp3juOdSOZ7AI4EHAad30kZ+DCdbh69VPp4L5vww4u0c6fd2sbyYg3p1sbzaNq3f3q8J/Kxt46ycq+d7+1Zyn4zkd8h8b9fttnO+C7BYXsDDgSM7028A3jDf5VqJ7fga8Hjqg5I2a2mbAWe29x8DntPJf2ab/xzgY530j7W0zYBfddJXyDfH27YFcDTwGODwdmL7A7DG8DGkjsjy8PZ+jZYvw8d1kG+hHH9gA+oP6wylL6njyfKnB9+5HZ/DgScupeMJbMWKP8RGfgwnW4evVT6W8/59msNtHcn3dr63axX3yazWq/O9PauwH9YFTqI+6X1WztXzvU0rsQ9G9jtkvrdt+GUXpv4GP2gGLmhpi0ZrHnsg9QrBpqWUi9qsi4FN2/vJtnOq9AsmSJ8P/wm8Dri1Td8F+GMp5eY23S3bbdvT5v+p5Z/p9s+1rYHLgP9tTaSfSLIeS+x4llIuBP4D+C1wEfX4nMjSO55dc3EMJ1uHVs1C/D7Nldn63i5KI6pXF5XWZedk4FLgKOoV89k6Vy82o/wdsqAYQIyJJOsDXwJeVUq5qjuv1BB3UQ/HleQpwKWllBPnuywjtga1C8FHSikPBK6lNpXfZokcz42AXakB018A6wE7z2uh5tBcHMOl8D3RwjJu36mlXq/2VUq5pZTyAOrV94cC281zkebFGP0OAQwgZuJCYMvO9BYtbcFLsib1JHdIKeXLLfmSJJu1+ZtRrxzA5Ns5VfoWE6TPtR2BpyU5D/gctflwf2DDJIPnnXTLdtv2tPkbAJcz8+2faxcAF5RSftamD6UGFEvteD4OOLeUclkp5Sbgy9RjvNSOZ9dcHMPJ1qFVsxC/T3Nltr63i8qI69VFqZTyR+AYajed2TpXLyaj/h2yoBhA9Hc8sG27m34t6g0vh81zmaaVJMAngV+WUj7QmXUYsKy9X0btwzlI36ONGrED8KfWJHsk8IQkG7Wrw0+g9uO7CLgqyQ5tXXt0ljVnSilvKKVsUUrZinpsvltKeS71ZPaslm14Owfb/6yWv7T03droCFsD21JvSF0Qx7+UcjHwuyT3akmPBc5giR1PatelHZKs28ox2M4ldTyHzMUxnGwdWjUL8fs0V2blezvXhV4Vo65X52QjZkmSjZNs2N6vQ70X5JfM3rl60ZiD3yELy3zfhLGYXtSRFM6i9u9703yXp2eZH0FtRj0VOLm9dqH2szsaOBv4DnDnlj/Af7dtPA3YvrOs5wPntNdenfTtgdPbZz7E0A2+87DNO7F89IN7Uv/xzgG+CKzd0u/Qps9p8+/Z+fyb2racSWcEooVy/IEHACe0Y/pV6ugdS+54Am8DftXK8mnqiBRL4ngCn6Xe23ETtVXpBXNxDCdbh69ZOaYL4vww4m0c6fd2sbyYg3p1sbyA+wE/b/vidOCtLX3WztWL8cWIfocspJdPopYkSZLUm12YJEmSJPVmACFJkiSpNwMISZIkSb0ZQEiSJEnqzQBCkiRJUm8GENIqSHJMkicOpb0qyUem+Mw1oy+ZJGk+WT9oKTOAkFbNZ6kPjOnaraVLksaX9YOWLAMIadUcCjy5PX2WJFsBfwH8PMnRSU5KclqSXYc/mGSnJId3pj+UZM/2/sFJvpfkxCRHJtlsLjZGkjRrrB+0ZBlASKuglHIF9QmST2pJuwFfAP4MPL2U8iDg0cD7k6TPMpOsCfwX8KxSyoOBA4F3znbZJUmjY/2gpWyN+S6AtAQMmqm/1v6+AAjwriSPBG4FNgc2BS7usbx7AfcFjmp1yurARbNfbEnSiFk/aEkygJBW3deADyZ5ELBuKeXE1tS8MfDgUspNSc4D7jD0uZtZsRVwMD/AL0opDx9tsSVJI2b9oCXJLkzSKiqlXAMcQ21KHtwctwFwaascHg3cY4KPng/cJ8naSTYEHtvSzwQ2TvJwqE3WSf56pBshSZp11g9aqmyBkGbHZ4GvsHzEjUOAryc5ATj5/7drxyYIBEEYRv+pwOYsTCzDZgRBEFO7MJkLvOiiCRRR3gsXFmaDZflgk9y2G7r7UVWnJJck9yTndf1ZVfskx6ra5XVPD0muHz8FAO/mfeDvVHd/ewYAAOBH+MIEAACMCQgAAGBMQAAAAGMCAi2kaYoAAAAeSURBVAAAGBMQAADAmIAAAADGBAQAADAmIAAAgLEFYyrSPSdd12EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5d7f2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化 'capital-gain'和'capital-loss' 两个特征\n",
    "vs.distribution(features_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于高度倾斜分布的特征如`'capital-gain'`和`'capital-loss'`，常见的做法是对数据施加一个<a href=\"https://en.wikipedia.org/wiki/Data_transformation_(statistics)\">对数转换</a>，将数据转换成对数，这样非常大和非常小的值不会对学习算法产生负面的影响。并且使用对数变换显著降低了由于异常值所造成的数据范围异常。但是在应用这个变换时必须小心：因为0的对数是没有定义的，所以我们必须先将数据处理成一个比0稍微大一点的数以成功完成对数转换。(Laplace smoothing)\n",
    "\n",
    "运行下面的代码单元来执行数据的转换和可视化结果。再次，注意值的范围和它们是如何分布的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1165b130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 对于倾斜的数据使用Log转换\n",
    "skewed = ['capital-gain', 'capital-loss']\n",
    "features_raw[skewed] = data[skewed].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "# 可视化对数转换后 'capital-gain'和'capital-loss' 两个特征\n",
    "vs.distribution(features_raw, transformed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 规一化数字特征\n",
    "除了对于高度倾斜的特征施加转换，对数值特征施加一些形式的缩放通常会是一个好的习惯。在数据上面施加一个缩放并不会改变数据分布的形式（比如上面说的'capital-gain' or 'capital-loss'）；但是，规一化保证了每一个特征在使用监督学习器的时候能够被平等的对待。注意一旦使用了缩放，观察数据的原始形式不再具有它本来的意义了，就像下面的例子展示的。\n",
    "\n",
    "运行下面的代码单元来规一化每一个数字特征。我们将使用[`sklearn.preprocessing.MinMaxScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)来完成这个任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30137</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age   workclass education_level  education-num  marital-status  \\\n",
       "0  0.30137   State-gov       Bachelors            0.8   Never-married   \n",
       "\n",
       "      occupation    relationship    race    sex  capital-gain  capital-loss  \\\n",
       "0   Adm-clerical   Not-in-family   White   Male       0.02174           0.0   \n",
       "\n",
       "   hours-per-week  native-country  \n",
       "0        0.397959   United-States  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 初始化一个 scaler，并将它施加到特征上\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "features_raw[numerical] = scaler.fit_transform(data[numerical])\n",
    "\n",
    "# 显示一个经过缩放的样例记录\n",
    "display(features_raw.head(n = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习：数据预处理\n",
    "\n",
    "从上面的**数据探索**中的表中，我们可以看到有几个属性的每一条记录都是非数字的。通常情况下，学习算法期望输入是数字的，这要求非数字的特征（称为类别变量）被转换。转换类别变量的一种流行的方法是使用**独热编码**方案。独热编码为每一个非数字特征的每一个可能的类别创建一个_“虚拟”_变量。例如，假设`someFeature`有三个可能的取值`A`，`B`或者`C`，。我们将把这个特征编码成`someFeature_A`, `someFeature_B`和`someFeature_C`.\n",
    "\n",
    "| 特征X |                    | 特征X_A | 特征X_B | 特征X_C |\n",
    "| :-: |                            | :-: | :-: | :-: |\n",
    "|  B  |  | 0 | 1 | 0 |\n",
    "|  C  | ----> 独热编码 ----> | 0 | 0 | 1 |\n",
    "|  A  |  | 1 | 0 | 0 |\n",
    "\n",
    "此外，对于非数字的特征，我们需要将非数字的标签`'income'`转换成数值以保证学习算法能够正常工作。因为这个标签只有两种可能的类别（\"<=50K\"和\">50K\"），我们不必要使用独热编码，可以直接将他们编码分别成两个类`0`和`1`，在下面的代码单元中你将实现以下功能：\n",
    " - 使用[`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies)对`'features_raw'`数据来施加一个独热编码。\n",
    " - 将目标标签`'income_raw'`转换成数字项。\n",
    "   - 将\"<=50K\"转换成`0`；将\">50K\"转换成`1`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 total features after one-hot encoding.\n"
     ]
    }
   ],
   "source": [
    "# TODO：使用pandas.get_dummies()对'features_raw'数据进行独热编码\n",
    "features = pd.get_dummies(features_raw)\n",
    "\n",
    "# TODO：将'income_raw'编码成数字值\n",
    "income = income_raw.apply(lambda x: 1 if x=='>50K' else 0)\n",
    "\n",
    "# 打印经过独热编码之后的特征数量\n",
    "encoded = list(features.columns)\n",
    "print (\"{} total features after one-hot encoding.\".format(len(encoded)))\n",
    "\n",
    "# 移除下面一行的注释以观察编码的特征名字\n",
    "#print encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混洗和切分数据\n",
    "现在所有的 _类别变量_ 已被转换成数值特征，而且所有的数值特征已被规一化。和我们一般情况下做的一样，我们现在将数据（包括特征和它们的标签）切分成训练和测试集。其中80%的数据将用于训练和20%的数据用于测试。然后再进一步把训练数据分为训练集和验证集，用来选择和优化模型。\n",
    "\n",
    "运行下面的代码单元来完成切分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 28941 samples.\n",
      "Validation set has 7236 samples.\n",
      "Testing set has 9045 samples.\n"
     ]
    }
   ],
   "source": [
    "# 导入 train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 将'features'和'income'数据切分成训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, income, test_size = 0.2, random_state = 0,\n",
    "                                                    stratify = income)\n",
    "# 将'X_train'和'y_train'进一步切分为训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0,\n",
    "                                                    stratify = y_train)\n",
    "\n",
    "# 显示切分的结果\n",
    "print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Validation set has {} samples.\".format(X_val.shape[0]))\n",
    "print (\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 评价模型性能\n",
    "在这一部分中，我们将尝试四种不同的算法，并确定哪一个能够最好地建模数据。四种算法包含一个*天真的预测器* 和三个你选择的监督学习器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评价方法和朴素的预测器\n",
    "*CharityML*通过他们的研究人员知道被调查者的年收入大于\\$50,000最有可能向他们捐款。因为这个原因*CharityML*对于准确预测谁能够获得\\$50,000以上收入尤其有兴趣。这样看起来使用**准确率**作为评价模型的标准是合适的。另外，把*没有*收入大于\\$50,000的人识别成年收入大于\\$50,000对于*CharityML*来说是有害的，因为他想要找到的是有意愿捐款的用户。这样，我们期望的模型具有准确预测那些能够年收入大于\\$50,000的能力比模型去**查全**这些被调查者*更重要*。我们能够使用**F-beta score**作为评价指标，这样能够同时考虑查准率和查全率：\n",
    "\n",
    "$$ F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{\\left( \\beta^2 \\cdot precision \\right) + recall} $$\n",
    "\n",
    "\n",
    "尤其是，当 $\\beta = 0.5$ 的时候更多的强调查准率，这叫做**F$_{0.5}$ score** （或者为了简单叫做F-score）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 1 - 天真的预测器的性能\n",
    "\n",
    "通过查看收入超过和不超过 \\$50,000 的人数，我们能发现多数被调查者年收入没有超过 \\$50,000。如果我们简单地预测说*“这个人的收入没有超过 \\$50,000”*，我们就可以得到一个 准确率超过 50% 的预测。这样我们甚至不用看数据就能做到一个准确率超过 50%。这样一个预测被称作是天真的。通常对数据使用一个*天真的预测器*是十分重要的，这样能够帮助建立一个模型表现是否好的基准。 使用下面的代码单元计算天真的预测器的相关性能。将你的计算结果赋值给`'accuracy'`, `‘precision’`, `‘recall’` 和 `'fscore'`，这些值会在后面被使用，请注意这里不能使用scikit-learn，你需要根据公式自己实现相关计算。\n",
    "\n",
    "*如果我们选择一个无论什么情况都预测被调查者年收入大于 \\$50,000 的模型，那么这个模型在**验证集上**的准确率，查准率，查全率和 F-score是多少？*  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Predictor on validation data: \n",
      "     Accuracy score: 0.2478 \n",
      "     Precision: 0.2478 \n",
      "     Recall: 1.0000 \n",
      "     F-score: 0.2917\n"
     ]
    }
   ],
   "source": [
    "#不能使用scikit-learn，你需要根据公式自己实现相关计算。\n",
    "\n",
    "y_val_pred = y_val.apply(lambda x:1)\n",
    "\n",
    "TP = sum(map(lambda x,y: 1 if x==1 and y==1 else 0, y_val, y_val_pred)) #True Pos\n",
    "FP = sum(map(lambda x,y: 1 if x==0 and y==1 else 0, y_val, y_val_pred)) #False Pos\n",
    "FN = sum(map(lambda x,y: 1 if x==1 and y==0 else 0, y_val, y_val_pred)) #False Neg\n",
    "\n",
    "#TODO： 计算准确率\n",
    "accuracy = float(TP) / (TP + FP)\n",
    "\n",
    "# TODO： 计算查准率 Precision\n",
    "precision = float(TP) / (TP + FP)\n",
    "\n",
    "# TODO： 计算查全率 Recall\n",
    "recall = float(TP) / (TP + FN)\n",
    "\n",
    "# TODO： 使用上面的公式，设置beta=0.5，计算F-score\n",
    "beta=0.5\n",
    "fscore = (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall)\n",
    "\n",
    "# 打印结果\n",
    "print (\"Naive Predictor on validation data: \\n \\\n",
    "    Accuracy score: {:.4f} \\n \\\n",
    "    Precision: {:.4f} \\n \\\n",
    "    Recall: {:.4f} \\n \\\n",
    "    F-score: {:.4f}\".format(accuracy, precision, recall, fscore))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 监督学习模型\n",
    "### 问题 2 - 模型应用\n",
    "\n",
    "你能够在 [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html) 中选择以下监督学习模型\n",
    "- 高斯朴素贝叶斯 (GaussianNB)\n",
    "- 决策树 (DecisionTree)\n",
    "- 集成方法 (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K近邻 (K Nearest Neighbors)\n",
    "- 随机梯度下降分类器 (SGDC)\n",
    "- 支撑向量机 (SVM)\n",
    "- Logistic回归（LogisticRegression）\n",
    "\n",
    "从上面的监督学习模型中选择三个适合我们这个问题的模型，并回答相应问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型1\n",
    "\n",
    "**模型名称**\n",
    "\n",
    "回答： 朴素贝叶斯\n",
    "\n",
    "\n",
    "**描述一个该模型在真实世界的一个应用场景。（你需要为此做点研究，并给出你的引用出处）**\n",
    "\n",
    "回答：\n",
    "\n",
    "**这个模型的优势是什么？他什么情况下表现最好？**\n",
    "\n",
    "回答：\n",
    "\n",
    "**这个模型的缺点是什么？什么条件下它表现很差？**\n",
    "\n",
    "回答：\n",
    "\n",
    "**根据我们当前数据集的特点，为什么这个模型适合这个问题。**\n",
    "\n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型2\n",
    "\n",
    "**模型名称**\n",
    "\n",
    "回答： adaboost\n",
    "\n",
    "\n",
    "**描述一个该模型在真实世界的一个应用场景。（你需要为此做点研究，并给出你的引用出处）**\n",
    "\n",
    "回答：\n",
    "\n",
    "**这个模型的优势是什么？他什么情况下表现最好？**\n",
    "\n",
    "回答：\n",
    "\n",
    "**这个模型的缺点是什么？什么条件下它表现很差？**\n",
    "\n",
    "回答：\n",
    "\n",
    "**根据我们当前数据集的特点，为什么这个模型适合这个问题。**\n",
    "\n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型3\n",
    "\n",
    "**模型名称**\n",
    "\n",
    "回答： SVM\n",
    "\n",
    "\n",
    "**描述一个该模型在真实世界的一个应用场景。（你需要为此做点研究，并给出你的引用出处）**\n",
    "\n",
    "回答：\n",
    "\n",
    "**这个模型的优势是什么？他什么情况下表现最好？**\n",
    "\n",
    "回答：\n",
    "\n",
    "**这个模型的缺点是什么？什么条件下它表现很差？**\n",
    "\n",
    "回答：\n",
    "\n",
    "**根据我们当前数据集的特点，为什么这个模型适合这个问题。**\n",
    "\n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Gaussian Naive Bayes (GaussianNB)\n",
    "\n",
    "- real-world application:\n",
    "\n",
    "- Text classification\n",
    "- spam detection\n",
    "- Categorize articles based on whether it is about healthy eating, politics, or even IT thematic.\n",
    "- Face recognition\n",
    "- Sentiment analysis\n",
    "- strengths of the model; when does it perform well?\n",
    "\n",
    "- Computationally fast and Simple to implement\n",
    "- Not sensitive to irrelevant features.\n",
    "- Works well with high dimensions\n",
    "- You need less training data\n",
    "- Good for few categories variables\n",
    "- Works with continuous and discrete data\n",
    "- Can be used for both multi-class and binary classification problems\n",
    "- weaknesses of the model; when does it perform poorly?\n",
    "\n",
    "- Relies on independence assumption and will perform badly if this assumption is not met (It accepts every feature is independent. This isn’t always the truth).\n",
    "- Fails estimating rare occurrences\n",
    "- If the model encounters unseen feature-label combination (not trained before). It will incorrectly estimate likelihood as 0 which can cause it to incorrectly classify the label.\n",
    "- What makes this model a good candidate for the problem, given what you know about the data?\n",
    "\n",
    "2- Decision Trees\n",
    "\n",
    "- real-world application:\n",
    "\n",
    "- In astronomy.\n",
    "- Recommendation system\n",
    "- strengths of the model; when does it perform well?\n",
    "\n",
    "- Can analyse both numerical and categorical data\n",
    "- Non-parametric so you don't have to worry about outliers or whether the data is linearly separable.\n",
    "- Work fast if is a simple structure.\n",
    "- weaknesses of the model; when does it perform poorly?\n",
    "\n",
    "- Tends to overfit with many features (but we can pick the optimal max-depth to avoid the problem)\n",
    "- What makes this model a good candidate for the problem, given what you know about the data?\n",
    "\n",
    "3- Ensemble Methods (Bagging)\n",
    "\n",
    "- real-world application:\n",
    "\n",
    "- Predict bankruptcy\n",
    "- strengths of the model; when does it perform well?\n",
    "\n",
    "- Robust against outliers and noise\n",
    "- Decrease the variance (overfitting)\n",
    "- weaknesses of the model; when does it perform poorly?\n",
    "\n",
    "- Slow when complex\n",
    "- Lack of transparency in underlying model\n",
    "- Sensitive to bias (underfitting).\n",
    "- What makes this model a good candidate for the problem, given what you know about the data?\n",
    "\n",
    "4- Ensemble Methods (AdaBoost)\n",
    "\n",
    "- real-world application:\n",
    "\n",
    "- Face detection (Binary classification where the model needs to classify if is a face or is a background image)\n",
    "- text classification\n",
    "- strengths of the model; when does it perform well?\n",
    "\n",
    "- Can be used by any type of data, textual, numeric, discrete.\n",
    "- Can be combined with any other learning algorithm\n",
    "- Automatically handles missing values\n",
    "- It doesn’t overfit easily\n",
    "- Simple to implement(Pre-processing is important)\n",
    "- Fast, versatile\n",
    "- weaknesses of the model; when does it perform poorly?\n",
    "\n",
    "- Sensitive to noisy data and outliers.\n",
    "- The performance depends on data and weak learner.\n",
    "- Weak classifiers too complex leads to overfitting or low margins.\n",
    "- Never the best in class predictions.\n",
    "- What makes this model a good candidate for the problem, given what you know about the data?\n",
    "\n",
    "5- Ensemble Methods (Gradient Boosting)\n",
    "\n",
    "- real-world application:\n",
    "\n",
    "- Search engines (solving the problem of learning to rank websites)\n",
    "- Ecology\n",
    "- Apt at almost any machine learning problem\n",
    "- strengths of the model; when does it perform well?\n",
    "\n",
    "- Robustness to outliers.\n",
    "- Fast training without sacrificing accuracy.\n",
    "- can handle different types of predictor variables (numerical, categorical) (heterogeneous features)\n",
    "- Automatically handles missing values\n",
    "- Best in class predictor\n",
    "- weaknesses of the model; when does it perform poorly?\n",
    "\n",
    " - Prone to over-fitting unless tree depth and learning rate are controlled correctly.\n",
    " - scalability.\n",
    " - since is sequential it can hardly be parallelized\n",
    " - slow in some cases (Long sequential computation times)\n",
    " - Sensitive to noisy data and outliers\n",
    " - Doesn’t work well without parameter tuning\n",
    " - GBDTs will usually perform better than RF, but they are harder to get right. More concretely, GBDTs have more hyper-parameters to tune and are also more prone to overfitting. RFs can almost work \"out of the box\" and that is one reason why they are very popular\n",
    "- What makes this model a good candidate for the problem, given what you know about the data?\n",
    "\n",
    "6- Ensemble Methods (Random Forest)\n",
    "\n",
    "- real-world application:\n",
    "\n",
    "- In the banking sector for finding the loyal and the fraud customers.\n",
    "- Video classification for YouTube (decide which video is appropriate or not)\n",
    "- In e-commerce and marketing, it used for identifying the possibility of a customer to like the recommended products base on the similar kinds of customers. \n",
    "- Image classification.\n",
    "- Apt at almost any machine learning problem\n",
    "- Bioinformatics\n",
    "- strengths of the model; when does it perform well?\n",
    "\n",
    "- Efficiently in large data sets\n",
    "- Is not parametric, therefore no formal distribution assumption.\n",
    "- highly accurate classifier (Maintains accuracy when a large proportion of data is missing).\n",
    "- Can be used for feature engineering (for identifying the most important features among the all available features in the training dataset).\n",
    "- Less likely to over-fit than a decision tree.\n",
    "- No need for preparation of the input data.\n",
    "- Generally train faster than SVMs\n",
    "- weaknesses of the model; when does it perform poorly?\n",
    "\n",
    "- Complexity (difficult to interpret)\n",
    "- Slow to evaluation (Time-consuming in comparison)\n",
    "- Need to choose the number of trees.\n",
    "- What makes this model a good candidate for the problem, given what you know about the data?\n",
    "\n",
    "7- K-Nearest Neighbors (KNeighbors)\n",
    "\n",
    "- real-world application:\n",
    "\n",
    "- Computer vision\n",
    "- text classifier (Multilabel tagging)\n",
    "- Recommender systems\n",
    "- Spell checking problems (best anomaly detection algorithms)\n",
    "- strengths of the model; when does it perform well?\n",
    "\n",
    "- KNN is not parametric\n",
    "- Is not influenced by noise in the data\n",
    "- Every decision is based on locality\n",
    "- Easy to implement\n",
    "- weaknesses of the model; when does it perform poorly?\n",
    "\n",
    "- The computation cost is very high since the algorithm hat to compute distance to all training samples which leads to the curse of dimensionality and if the number of features increse ,the computational cost increase exponentially\n",
    "- hard to find what K distance function should use without experimentation. Therefore, are hard to interpret it.\n",
    "- The query time of KNNs is higher than the training time, since is a lazy learner.\n",
    "- What makes this model a good candidate for the problem, given what you know about the data?\n",
    "\n",
    "8- Stochastic Gradient Descent Classifier (SGDC)\n",
    "\n",
    "- real-world application:\n",
    "\n",
    "- Text classification and natural language processing.\n",
    "- strengths of the model; when does it perform well?\n",
    "\n",
    "- weaknesses of the model; when does it perform poorly?\n",
    "\n",
    "- Sensitive to feature scaling(terrible performance if don’t do feature scaling).\n",
    "- Require several hyperparameters such as the regularization parameter and the number of iterations.\n",
    "- Sometimes calculating the gradient can be very expensive or intractable if the size of your data is large.\n",
    "- What makes this model a good candidate for the problem, given what you know about the data?\n",
    "\n",
    "9- Support Vector Machines (SVM)\n",
    "\n",
    "- real-world application:\n",
    "\n",
    "- Text classification\n",
    "- Image recognition\n",
    "- Handwritten digit identification\n",
    "- strengths of the model; when does it perform well?\n",
    "\n",
    "- Works well in complex domains where there is not a clear margin of separation.\n",
    "- Perform well with non-linear boundary (depends of the kernel used)\n",
    "- Handle high dimensional data well\n",
    "- Great accuracy.\n",
    "- weaknesses of the model; when does it perform poorly?\n",
    "\n",
    "- Don’t perform well in larger data sets, because the training time happens to be cubic to the size of the data set.\n",
    "- Needs fine tune the parameters\n",
    "- Don’t work well with noise data. So, where the classes are very overlapping, you must count independent evidence (Susceptible to over-fitting when the data has noisy or overlaps)\n",
    "- What makes this model a good candidate for the problem, given what you know about the data?\n",
    "\n",
    "10- Logistic Regression\n",
    "\n",
    "- real-world application:\n",
    "\n",
    "- Medical outcomes (survival studies)\n",
    "- Social science (treatment effects)\n",
    "- Ordering results by probability\n",
    "- Modelling marketing responses\n",
    "- strengths of the model; when does it perform well?\n",
    "\n",
    "- Low Variance\n",
    "- Robust to noise\n",
    "- Can be used in big data.\n",
    "- Using L1 & L2 regularization is effective in feature selection\n",
    "- The best algorithm for predicting probabilities of an event\n",
    "- weaknesses of the model; when does it perform poorly?\n",
    "\n",
    "- Can hardly handle categorical features.\n",
    "- High bias\n",
    "- You must assume the features are roughly linear and the problem is linearly separable.\n",
    "- Limited to capture complex features in the data, when are not linear.\n",
    "- Can suffer from outliers\n",
    "- What makes this model a good candidate for the problem, given what you know about the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习 - 创建一个训练和预测的流水线\n",
    "为了正确评估你选择的每一个模型的性能，创建一个能够帮助你快速有效地使用不同大小的训练集并在验证集上做预测的训练和验证的流水线是十分重要的。\n",
    "你在这里实现的功能将会在接下来的部分中被用到。在下面的代码单元中，你将实现以下功能：\n",
    "\n",
    " - 从[`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)中导入`fbeta_score`和`accuracy_score`。\n",
    " - 用训练集拟合学习器，并记录训练时间。\n",
    " - 对训练集的前300个数据点和验证集进行预测并记录预测时间。\n",
    " - 计算预测训练集的前300个数据点的准确率和F-score。\n",
    " - 计算预测验证集的准确率和F-score。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import two metrics from sklearn - fbeta_score and accuracy_score.  \n",
    "# We already did this above, but do it again as requested :)\n",
    "from sklearn.metrics import accuracy_score, fbeta_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    results = {}\n",
    "    \n",
    "    # Fit the learner to the training data using slicing with 'sample_size'\n",
    "    start = time() # Get start time\n",
    "    learner.fit(X_train.head(sample_size), y_train.head(sample_size))\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # Get the predictions on the test set,\n",
    "    #       then get predictions on the first 300 training samples\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # Compute accuracy on the first 300 training samples\n",
    "    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n",
    "        \n",
    "    # Compute accuracy on test set\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "    \n",
    "    # Compute F-score on the the first 300 training samples. We use previous beta\n",
    "    results['f_train'] = fbeta_score(y_train[:300], predictions_train, beta)\n",
    "        \n",
    "    # Compute F-score on the test set. We use previous beta\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, beta)\n",
    "       \n",
    "    # Success\n",
    "    print (\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习：初始模型的评估\n",
    "在下面的代码单元中，您将需要实现以下功能：             \n",
    "- 导入你在前面讨论的三个监督学习模型。             \n",
    "- 初始化三个模型并存储在`'clf_A'`，`'clf_B'`和`'clf_C'`中。\n",
    "  - 使用模型的默认参数值，在接下来的部分中你将需要对某一个模型的参数进行调整。             \n",
    "  - 设置`random_state`  (如果有这个参数)。       \n",
    "- 计算1%， 10%， 100%的训练数据分别对应多少个数据点，并将这些值存储在`'samples_1'`, `'samples_10'`, `'samples_100'`中\n",
    "\n",
    "**注意：**取决于你选择的算法，下面实现的代码可能需要一些时间来运行！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB trained on 289 samples.\n",
      "GaussianNB trained on 2894 samples.\n",
      "GaussianNB trained on 28941 samples.\n",
      "DecisionTreeClassifier trained on 289 samples.\n",
      "DecisionTreeClassifier trained on 2894 samples.\n",
      "DecisionTreeClassifier trained on 28941 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tianjiayang\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC trained on 289 samples.\n",
      "SVC trained on 2894 samples.\n",
      "SVC trained on 28941 samples.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-f7d1d211a72b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Run metrics visualization for the three supervised learning models chosen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\udacity_ml_degree\\project2_finding_donors\\visuals.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(results, accuracy, f1)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[1;31m# Creative plot code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;31m# ax[j/3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m                 \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.45\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"1%\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"10%\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"100%\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1157d110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the three models\n",
    "clf_A = GaussianNB()\n",
    "clf_B = DecisionTreeClassifier(criterion=\"entropy\",random_state=0)\n",
    "clf_C = SVC(random_state=0)\n",
    "\n",
    "# Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "def get_sample_size(percentage):\n",
    "    return int((float(percentage)/100)*X_train.shape[0])\n",
    "\n",
    "samples_1 = get_sample_size(1.0)\n",
    "samples_10 = get_sample_size(10.0)\n",
    "samples_100 = get_sample_size(100.0)\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Run metrics visualization for the three supervised learning models chosen\n",
    "vs.evaluate(results, accuracy, fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 提高效果\n",
    "\n",
    "在这最后一节中，您将从三个有监督的学习模型中选择 *最好的* 模型来使用学生数据。你将在整个训练集（`X_train`和`y_train`）上使用网格搜索优化至少调节一个参数以获得一个比没有调节之前更好的 F-score。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 3 - 选择最佳的模型\n",
    "\n",
    "*基于你前面做的评价，用一到两段话向 *CharityML* 解释这三个模型中哪一个对于判断被调查者的年收入大于 \\$50,000 是最合适的。*             \n",
    "**提示：**你的答案应该包括评价指标，预测/训练时间，以及该算法是否适合这里的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 4 - 用通俗的话解释模型\n",
    "\n",
    "*用一到两段话，向 *CharityML* 用外行也听得懂的话来解释最终模型是如何工作的。你需要解释所选模型的主要特点。例如，这个模型是怎样被训练的，它又是如何做出预测的。避免使用高级的数学或技术术语，不要使用公式或特定的算法名词。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答： ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习：模型调优\n",
    "调节选择的模型的参数。使用网格搜索（GridSearchCV）来至少调整模型的重要参数（至少调整一个），这个参数至少需尝试3个不同的值。你要使用整个训练集来完成这个过程。在接下来的代码单元中，你需要实现以下功能：\n",
    "\n",
    "- 导入[`sklearn.model_selection.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) 和 [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- 初始化你选择的分类器，并将其存储在`clf`中。\n",
    " - 设置`random_state` (如果有这个参数)。\n",
    "- 创建一个对于这个模型你希望调整参数的字典。\n",
    " - 例如: parameters = {'parameter' : [list of values]}。\n",
    " - **注意：** 如果你的学习器有 `max_features` 参数，请不要调节它！\n",
    "- 使用`make_scorer`来创建一个`fbeta_score`评分对象（设置$\\beta = 0.5$）。\n",
    "- 在分类器clf上用'scorer'作为评价函数运行网格搜索，并将结果存储在grid_obj中。\n",
    "- 用训练集（X_train, y_train）训练grid search object,并将结果存储在`grid_fit`中。\n",
    "\n",
    "**注意：** 取决于你选择的参数列表，下面实现的代码可能需要花一些时间运行！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO：导入'GridSearchCV', 'make_scorer'和其他一些需要的库\n",
    "\n",
    "# TODO：初始化分类器\n",
    "clf = None\n",
    "\n",
    "# TODO：创建你希望调节的参数列表\n",
    "parameters = None\n",
    "\n",
    "# TODO：创建一个fbeta_score打分对象\n",
    "scorer = None\n",
    "\n",
    "# TODO：在分类器上使用网格搜索，使用'scorer'作为评价函数\n",
    "grid_obj = None\n",
    "\n",
    "# TODO：用训练数据拟合网格搜索对象并找到最佳参数\n",
    "\n",
    "# 得到estimator\n",
    "best_clf = grid_obj.best_estimator_\n",
    "\n",
    "# 使用没有调优的模型做预测\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_val)\n",
    "best_predictions = best_clf.predict(X_val)\n",
    "\n",
    "# 汇报调参前和调参后的分数\n",
    "print \"Unoptimized model\\n------\"\n",
    "print \"Accuracy score on validation data: {:.4f}\".format(accuracy_score(y_val, predictions))\n",
    "print \"F-score on validation data: {:.4f}\".format(fbeta_score(y_val, predictions, beta = 0.5))\n",
    "print \"\\nOptimized Model\\n------\"\n",
    "print \"Final accuracy score on the validation data: {:.4f}\".format(accuracy_score(y_val, best_predictions))\n",
    "print \"Final F-score on the validation data: {:.4f}\".format(fbeta_score(y_val, best_predictions, beta = 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 5 - 最终模型评估\n",
    "\n",
    "_你的最优模型在测试数据上的准确率和 F-score 是多少？这些分数比没有优化的模型好还是差？你优化的结果相比于你在**问题 1**中得到的天真预测器怎么样？_  \n",
    "**注意：**请在下面的表格中填写你的结果，然后在答案框中提供讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 结果:\n",
    " \n",
    "| 评价指标         | 天真预测器           | 未优化的模型        | 优化的模型        |\n",
    "| :------------: | :-----------------: | :---------------: | :-------------: | \n",
    "| 准确率          |                     |                   |                 |\n",
    "| F-score        |                     |                   |                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 特征的重要性\n",
    "\n",
    "在数据上（比如我们这里使用的人口普查的数据）使用监督学习算法的一个重要的任务是决定哪些特征能够提供最强的预测能力。专注于少量的有效特征和标签之间的关系，我们能够更加简单地理解这些现象，这在很多情况下都是十分有用的。在这个项目的情境下这表示我们希望选择一小部分特征，这些特征能够在预测被调查者是否年收入大于\\$50,000这个问题上有很强的预测能力。\n",
    "\n",
    "选择一个有 `'feature_importance_'` 属性的scikit学习分类器（例如 AdaBoost，随机森林）。`'feature_importance_'` 属性是对特征的重要性排序的函数。在下一个代码单元中用这个分类器拟合训练集数据并使用这个属性来决定人口普查数据中最重要的5个特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 6 - 观察特征相关性\n",
    "\n",
    "当**探索数据**的时候，它显示在这个人口普查数据集中每一条记录我们有十三个可用的特征。             \n",
    "_在这十三个记录中，你认为哪五个特征对于预测是最重要的，选择每个特征的理由是什么？你会怎样对他们排序？_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**\n",
    "- 特征1:\n",
    "- 特征2:\n",
    "- 特征3:\n",
    "- 特征4:\n",
    "- 特征5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习 - 提取特征重要性\n",
    "\n",
    "选择一个`scikit-learn`中有`feature_importance_`属性的监督学习分类器，这个属性是一个在做预测的时候根据所选择的算法来对特征重要性进行排序的功能。\n",
    "\n",
    "在下面的代码单元中，你将要实现以下功能：\n",
    " - 如果这个模型和你前面使用的三个模型不一样的话从sklearn中导入一个监督学习模型。\n",
    " - 在整个训练集上训练一个监督学习模型。\n",
    " - 使用模型中的 `'feature_importances_'`提取特征的重要性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO：导入一个有'feature_importances_'的监督学习模型\n",
    "\n",
    "# TODO：在训练集上训练一个监督学习模型\n",
    "model = None\n",
    "\n",
    "# TODO： 提取特征重要性\n",
    "importances = None\n",
    "\n",
    "# 绘图\n",
    "vs.feature_plot(importances, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 7 - 提取特征重要性\n",
    "观察上面创建的展示五个用于预测被调查者年收入是否大于\\$50,000最相关的特征的可视化图像。\n",
    "\n",
    "_这五个特征的权重加起来是否超过了0.5?_<br>\n",
    "_这五个特征和你在**问题 6**中讨论的特征比较怎么样？_<br>\n",
    "_如果说你的答案和这里的相近，那么这个可视化怎样佐证了你的想法？_<br>\n",
    "_如果你的选择不相近，那么为什么你觉得这些特征更加相关？_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择\n",
    "\n",
    "如果我们只是用可用特征的一个子集的话模型表现会怎么样？通过使用更少的特征来训练，在评价指标的角度来看我们的期望是训练和预测的时间会更少。从上面的可视化来看，我们可以看到前五个最重要的特征贡献了数据中**所有**特征中超过一半的重要性。这提示我们可以尝试去**减小特征空间**，简化模型需要学习的信息。下面代码单元将使用你前面发现的优化模型，并**只使用五个最重要的特征**在相同的训练集上训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入克隆模型的功能\n",
    "from sklearn.base import clone\n",
    "\n",
    "# 减小特征空间\n",
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "X_val_reduced = X_val[X_val.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "\n",
    "# 在前面的网格搜索的基础上训练一个“最好的”模型\n",
    "clf_on_reduced = (clone(best_clf)).fit(X_train_reduced, y_train)\n",
    "\n",
    "# 做一个新的预测\n",
    "reduced_predictions = clf_on_reduced.predict(X_val_reduced)\n",
    "\n",
    "# 对于每一个版本的数据汇报最终模型的分数\n",
    "print \"Final Model trained on full data\\n------\"\n",
    "print \"Accuracy on validation data: {:.4f}\".format(accuracy_score(y_val, best_predictions))\n",
    "print \"F-score on validation data: {:.4f}\".format(fbeta_score(y_val, best_predictions, beta = 0.5))\n",
    "print \"\\nFinal Model trained on reduced data\\n------\"\n",
    "print \"Accuracy on validation data: {:.4f}\".format(accuracy_score(y_val, reduced_predictions))\n",
    "print \"F-score on validation data: {:.4f}\".format(fbeta_score(y_val, reduced_predictions, beta = 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 8 - 特征选择的影响\n",
    "\n",
    "*最终模型在只是用五个特征的数据上和使用所有的特征数据上的 F-score 和准确率相比怎么样？*  \n",
    "*如果训练时间是一个要考虑的因素，你会考虑使用部分特征的数据作为你的训练集吗？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 9 - 在测试集上测试你的模型\n",
    "\n",
    "终于到了测试的时候，记住，测试集只能用一次。\n",
    "\n",
    "*使用你最有信心的模型，在测试集上测试，计算出准确率和 F-score。*\n",
    "*简述你选择这个模型的原因，并分析测试结果*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO test your model on testing data and report accuracy and F score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **注意：** 当你写完了所有的代码，并且回答了所有的问题。你就可以把你的 iPython Notebook 导出成 HTML 文件。你可以在菜单栏，这样导出**File -> Download as -> HTML (.html)**把这个 HTML 和这个 iPython notebook 一起做为你的作业提交。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
